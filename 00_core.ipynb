{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire Split\n",
    "\n",
    "> Split individual fire events from tif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from IPython.core.debugger import set_trace\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "from rasterio.crs import CRS\n",
    "from shapely.geometry import MultiPolygon\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def read_data(filename):\n",
    "    data = rasterio.open(filename)\n",
    "    meta = data.meta\n",
    "    crs  = data.crs\n",
    "    transform = data.transform\n",
    "    data = data.read().squeeze()\n",
    "    data[data<0] = 0\n",
    "    return data, meta, crs, transform\n",
    "\n",
    "def save_data(filename, raster, meta=None, crs=None, transform=None):\n",
    "    if meta is None:\n",
    "        assert crs is not None\n",
    "        assert transform is not None\n",
    "        shp = raster.shape\n",
    "        if len(shp) == 2: \n",
    "            count = 1\n",
    "            height, width = shp\n",
    "        elif len(shp) == 3: \n",
    "            count, height, width = shp\n",
    "        else: raise NotImplementedError\n",
    "        meta = {'driver': 'GTiff', 'dtype': 'uint32', \n",
    "                'nodata': 0, 'width': width, 'height': height, \n",
    "                'count': count, 'crs': crs, \n",
    "                'transform': transform}\n",
    "    else:\n",
    "        meta['nodata'] = 0\n",
    "        meta['dtype'] = 'uint32'\n",
    "    meta['compress'] = 'lzw'\n",
    "    with rasterio.open(filename, 'w', **meta) as dst:\n",
    "        if len(raster.shape) == 2:\n",
    "            raster = raster[None]\n",
    "        dst.write(raster.astype('uint32'))\n",
    "\n",
    "def split_fires(data, interval_days=4, interval_pixels=4, min_size_pixels=1,\n",
    "                min_daily_size=1):\n",
    "    data = data.astype(np.uint32)\n",
    "    kernel = np.ones((interval_pixels,interval_pixels))\n",
    "    data_conv = ndimage.convolve(data>0, kernel, mode='constant', cval=0.0)>0\n",
    "    \n",
    "    # Initial labels with no temporal separation\n",
    "    labels, nlabels = ndimage.label(data_conv)\n",
    "    labels[data == 0] = 0\n",
    "    del data_conv\n",
    "    \n",
    "    # Remove fires with less than min_size_pixels\n",
    "    classes = np.arange(0, np.max(labels)+1, 1)\n",
    "    ba_size_pixels = np.bincount(labels.reshape(-1))\n",
    "    labels[np.isin(labels,classes[ba_size_pixels < min_size_pixels])] = 0\n",
    "    \n",
    "    # Calculate unique (data, label) pairs ignoring no fire pixels\n",
    "    data_aux = data[labels>0]\n",
    "    labels_aux = labels[labels>0]\n",
    "    #unique_pairs = np.unique(np.array((data_aux, labels_aux), dtype=np.uint32).reshape(2,-1), axis=1)\n",
    "    unique_labels = np.unique(labels_aux)\n",
    "    unique_dates = []\n",
    "    for i in unique_labels:\n",
    "        a = np.argwhere(np.bincount(data[labels==i].reshape(-1)) >= min_daily_size).reshape(-1)\n",
    "        unique_dates.append(a)\n",
    "    del data_aux, labels_aux\n",
    "    \n",
    "    # Find shapes that need time separation\n",
    "    df = pd.DataFrame({'date': unique_dates, 'label': unique_labels})\n",
    "    try:\n",
    "        df_overlap = df.groupby('label').agg(lambda x : len(x.values[0]))\n",
    "    except:\n",
    "        df_overlap = df.groupby('label').agg(lambda x : len(x[0]))\n",
    "    overlap_index = df_overlap.loc[df_overlap.date>1].index\n",
    "    #df = df.groupby('label').agg(lambda x : x.values.tolist())\n",
    "    df = df.loc[df.label.isin(overlap_index)]\n",
    "    df['splits'] = [np.diff(df.iloc[i].date) > interval_days for i in range(len(df))]\n",
    "        \n",
    "    for k in tqdm(range(len(df))):\n",
    "        df_row = df.iloc[k]\n",
    "        for i, s in enumerate(df_row.splits):\n",
    "            if s:\n",
    "                split1 = df_row.date[i]\n",
    "                I1 = (labels==df_row.label) & (data<=split1)\n",
    "                I1_conv = ndimage.convolve(I1, kernel, mode='constant', cval=0.0)>0\n",
    "                l1, _ = ndimage.label(I1_conv)\n",
    "                l1[I1==0] = 0\n",
    "                l1[l1>0] += labels.max()\n",
    "                labels[I1] = l1[I1]\n",
    "                if i == np.where(df_row.splits)[0][-1]:\n",
    "                    I1 = (labels==df_row.label) & (data>split1)\n",
    "                    I1_conv = ndimage.convolve(I1, kernel, mode='constant', cval=0.0)>0\n",
    "                    l1, _ = ndimage.label(I1_conv)\n",
    "                    l1[I1==0] = 0\n",
    "                    l1[l1>0] += labels.max()\n",
    "                    labels[I1] = l1[I1]\n",
    "\n",
    "    # Relabel\n",
    "    _, labels = np.unique(labels,return_inverse=1)\n",
    "    labels = labels.reshape(data.shape)\n",
    "        \n",
    "    # Remove fires with less than min_size_pixels\n",
    "    classes = np.arange(0, np.max(labels)+1, 1)\n",
    "    ba_size_pixels = np.bincount(labels.reshape(-1))\n",
    "    labels[np.isin(labels,classes[ba_size_pixels < min_size_pixels])] = 0\n",
    "    \n",
    "    # Relabel\n",
    "    _, labels = np.unique(labels,return_inverse=1)\n",
    "    labels = labels.reshape(data.shape)\n",
    "    labels[data==0] = 0\n",
    "    \n",
    "    # Calculate unique (data, label) pairs ignoring no fire pixels\n",
    "    data_aux = data[labels>0]\n",
    "    labels_aux = labels[labels>0]\n",
    "    unique_pairs = np.unique(np.array((data_aux, labels_aux), dtype=np.uint32).reshape(2,-1), axis=1)\n",
    "    del data_aux, labels_aux\n",
    "\n",
    "    # Find min and max dates\n",
    "    df = pd.DataFrame({'date': unique_pairs[0], 'label_id': unique_pairs[1]})\n",
    "    df = df.groupby('label_id').agg({'date' : [np.min, np.max]})\n",
    "    df = df.reset_index()\n",
    "    df = pd.DataFrame({'label_id': df.label_id, 'tstart': df.date.amin, \n",
    "                       'tend': df.date.amax})\n",
    "    return labels, df\n",
    "\n",
    "def to_polygon(data, crs, transform, base_df, area_epsg=None):\n",
    "    geoms = list({'properties': {'value': v}, 'geometry': s}\n",
    "        for i, (s, v) in enumerate(rasterio.features.shapes(data.astype(np.uint16), transform=transform))\n",
    "    )\n",
    "    df = gpd.GeoDataFrame.from_features(geoms, crs=crs)\n",
    "    df = df.loc[df.value>0].reset_index(drop=True)\n",
    "    geoms = []\n",
    "    for i in range(1, int(df.value.max())+1):\n",
    "        polys = df.loc[df.value==i].geometry.values\n",
    "        if len(polys) > 0:\n",
    "            mpoly = MultiPolygon(polys)\n",
    "            geoms.append(mpoly)\n",
    "    df = gpd.GeoDataFrame({'label_id': list(range(1, int(df.value.max())+1)),\n",
    "                           'geometry': geoms}, crs=crs)\n",
    "    df = df.merge(base_df, how='left', on='label_id')\n",
    "    if area_epsg is None:\n",
    "        df['area_ha'] = df.area*0.0001\n",
    "    else:\n",
    "        df['area_ha'] = np.round((df.to_crs(epsg=area_epsg).area.values*0.0001), 2)\n",
    "    return df\n",
    "\n",
    "def run_all(input_path, save_path, interval_days=4, interval_pixels=4, \n",
    "            min_size_pixels=1, save_tif=True, save_shape=False):\n",
    "    if input_path.is_dir():\n",
    "        files = list(input_path.iterdir())\n",
    "        files = [f for f in files if 'tif' in f.suffix]\n",
    "    else:\n",
    "        files = [input_path]\n",
    "    \n",
    "    for f in tqdm(files):\n",
    "        fsave = save_path/f'{f.stem}_labels'\n",
    "        data, meta, crs, transform = read_data(f)\n",
    "        meta.update(compress='lzw')\n",
    "        labels, df = split_fires(data, \n",
    "                                 interval_days=interval_days, \n",
    "                                 interval_pixels=interval_pixels,\n",
    "                                 min_size_pixels=min_size_pixels)            \n",
    "        if save_tif: save_data(str(fsave) + '.tif', labels, meta)\n",
    "        if save_shape:\n",
    "            df = to_polygon(labels, crs, transform, df)\n",
    "            df.to_file(str(fsave) + '.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Example:\n",
    "run_all(Path('../'),\n",
    "        Path('../output'), \n",
    "        interval_days=16,  \n",
    "        interval_pixels=8, \n",
    "        min_size_pixels=100,\n",
    "        save_shape=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_cli.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastai_dev)",
   "language": "python",
   "name": "fastai_dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
